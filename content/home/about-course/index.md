---
# About/Biography widget.
widget: "blank"
headless: true
active: true
date: 2018-12-13T00:00:00

# Order that this section will appear in.
weight: 10

design:
  columns: "1"
---

# Test Computing Soc SC <img src="img/cis.svg" align="right" />

* Instructor: Sabrina Nardin
* Teaching Assistants:
    * TBA
    * TBA
* Meeting day/time: Tu-Th 3:30-4:50
* Meeting location: 
* Office hours:
    * Sabrina: Tu 9-11am (MACSS Blds. 221A)
    * TA1: M 5:30-7:30pm ()
    * TA2: F 11-12pm (), 12-1pm ()
* Prerequisites: None
* Requirements: Internet connection and a computer

## Course Description

This is an applied course for data scientists with little-to-no programming experience who wish to harness growing digital and computational resources. The focus of the course is on generating **reproducible research** through the use of programming languages and version control software. Major emphasis is placed on a pragmatic understanding of core principles of programming and packaged implementations of methods. Students will leave the course with basic computational skills implemented through many computational methods and approaches to data science; while students will not become expert programmers, they will gain the knowledge of how to adapt and expand these skills as they are presented with new questions, methods, and data.

## Course Objectives

By the end of the course, students will:

* Construct and execute basic programs in R using elementary programming techniques and [`tidyverse`](http://tidyverse.org/) packages (e.g. loops, conditional statements, user-defined functions)
* Apply stylistic principles of coding to generate reusable, interpretable code
* Debug programs for errors
* Identify and use external libraries to expand on base functions
* Apply Git and GitHub workflows for version control
* Publish reproducible documents
* Implement best practices for reproducible research
* Implement machine learning algorithms
* Visualize information and data using appropriate graphical techniques
* Import data from files or the internet
* Munge raw data into a tidy format
* Scrape websites to collect data for analysis
* Create visualizations using geospatial data
* Parse and analyze text documents
* Construct interactive web applications
